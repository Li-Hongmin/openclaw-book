# ç¬¬11ç« ï¼šåŸºç¡€è®¾æ–½ä¸DevOpsè‡ªåŠ¨åŒ–

> "åŸºç¡€è®¾æ–½ä¸åº”è¯¥éœ€è¦äººç±»24å°æ—¶å¾…å‘½ã€‚Agentå¯ä»¥æˆä¸ºæ°¸ä¸ä¼‘æ¯çš„è¿ç»´å·¥ç¨‹å¸ˆã€‚"

å‡Œæ™¨3ç‚¹,ä½ çš„æ‰‹æœºå“äº†ã€‚ç”Ÿäº§ç¯å¢ƒçš„Kubernetesé›†ç¾¤å‡ºç°äº†Podå´©æºƒ,ç›‘æ§ç³»ç»Ÿå‘å‡ºäº†å‘Šè­¦ã€‚ä½ ç¡çœ¼æƒºå¿ªåœ°çˆ¬èµ·æ¥,SSHç™»å½•æœåŠ¡å™¨,æ£€æŸ¥æ—¥å¿—,é‡å¯æœåŠ¡,ç„¶åç¥ˆç¥·ä¸ä¼šå†æœ‰é—®é¢˜ã€‚ç¬¬äºŒå¤©ä¸€æ—©,ä½ ç–²æƒ«ä¸å ªåœ°å›åˆ°åŠå…¬å®¤,å‘èª“è¦"æ‰¾æ—¶é—´"è‡ªåŠ¨åŒ–è¿™äº›é‡å¤çš„è¿ç»´å·¥ä½œã€‚

ä½†æ—¶é—´æ°¸è¿œä¸å¤Ÿã€‚ç›´åˆ°ä½ é‡åˆ°äº†Agentã€‚

æœ¬ç« å°†å±•ç¤ºå¦‚ä½•æ„å»º**è‡ªæ„ˆå¼åŸºç¡€è®¾æ–½ç³»ç»Ÿ**(Self-healing Infrastructure),è®©AI Agentæˆä¸ºä½ çš„24/7è¿ç»´åŠ©æ‰‹ã€‚å®ƒä¸ä»…èƒ½ç›‘æ§ç³»ç»Ÿå¥åº·çŠ¶æ€,è¿˜èƒ½è‡ªä¸»è¯Šæ–­é—®é¢˜ã€æ‰§è¡Œä¿®å¤æ“ä½œã€ç®¡ç†åŸºç¡€è®¾æ–½å˜æ›´,å¹¶åœ¨å¿…è¦æ—¶å”¤é†’ä½ ã€‚

## 11.1 ä¸ºä»€ä¹ˆåŸºç¡€è®¾æ–½éœ€è¦Agent

### ä¼ ç»Ÿè¿ç»´çš„ä¸‰å¤§ç—›ç‚¹

**1. 24/7å¾…å‘½çš„ç–²æƒ«**

ç°ä»£åŸºç¡€è®¾æ–½æ°¸ä¸ä¼‘æ¯,ä½†äººç±»éœ€è¦ç¡çœ ã€‚ä¼ ç»Ÿçš„è§£å†³æ–¹æ¡ˆæ˜¯è½®ç­å€¼ç­,ä½†è¿™å¸¦æ¥äº†é«˜æ˜‚çš„äººåŠ›æˆæœ¬å’Œç”Ÿæ´»è´¨é‡ä¸‹é™ã€‚

```
ä¼ ç»Ÿè¿ç»´æµç¨‹:
å‘Šè­¦è§¦å‘ â†’ äººç±»æ”¶åˆ°é€šçŸ¥ â†’ ç™»å½•ç³»ç»Ÿ 
â†’ æŸ¥çœ‹æ—¥å¿— â†’ è¯Šæ–­é—®é¢˜ â†’ æ‰§è¡Œä¿®å¤ 
â†’ éªŒè¯ç»“æœ â†’ è®°å½•æ–‡æ¡£

å¹³å‡å“åº”æ—¶é—´: 15-30åˆ†é’Ÿ(å¦‚æœäººåœ¨ç¡è§‰å¯èƒ½æ›´é•¿)
```

**2. é‡å¤æ€§å·¥ä½œçš„ä½æ•ˆ**

æ ¹æ®è°ƒæŸ¥,çº¦70%çš„è¿ç»´æ•…éšœæ˜¯"æ›¾ç»è§è¿‡çš„é—®é¢˜"ã€‚æ¯æ¬¡éƒ½éœ€è¦äººå·¥æ‰§è¡Œç›¸åŒçš„è¯Šæ–­å’Œä¿®å¤æ­¥éª¤,æ—¢æµªè´¹æ—¶é—´åˆå®¹æ˜“å‡ºé”™ã€‚

å¸¸è§çš„é‡å¤åœºæ™¯:
- **Podå†…å­˜æº¢å‡ºå´©æºƒ** â†’ é‡å¯Pod,æ¸…ç†ç¼“å­˜
- **ç£ç›˜ç©ºé—´ä¸è¶³** â†’ æ¸…ç†æ—¥å¿—,æ‰©å®¹å­˜å‚¨
- **è¯ä¹¦å³å°†è¿‡æœŸ** â†’ ç»­æœŸè¯ä¹¦,é‡å¯æœåŠ¡
- **éƒ¨ç½²å¤±è´¥** â†’ å›æ»šåˆ°ä¸Šä¸€ä¸ªç¨³å®šç‰ˆæœ¬
- **æ•°æ®åº“è¿æ¥æ± è€—å°½** â†’ é‡å¯åº”ç”¨,è°ƒæ•´é…ç½®

**3. çŸ¥è¯†æ•£è½ä¸ç»éªŒæµå¤±**

è¿ç»´çŸ¥è¯†å¾€å¾€å­˜åœ¨äºèµ„æ·±å·¥ç¨‹å¸ˆçš„å¤§è„‘ä¸­,æˆ–è€…æ•£è½åœ¨Confluenceã€Slackå†å²æ¶ˆæ¯ã€ç§äººç¬”è®°é‡Œã€‚å½“å…³é”®äººå‘˜ç¦»èŒæ—¶,è¿™äº›å®è´µçš„çŸ¥è¯†ä¹Ÿéšä¹‹æµå¤±ã€‚

> ğŸ’¡ **AIè¾…åŠ©æç¤º**
> 
> ä¸ç†Ÿæ‚‰Kubernetesã€Dockeræˆ–DevOpsæ¦‚å¿µ?æ²¡å…³ç³»!é‡åˆ°ä¸æ‡‚çš„æœ¯è¯­,éšæ—¶é—®AI:
> - "ä»€ä¹ˆæ˜¯Kubernetes Pod?ä¸ºä»€ä¹ˆä¼šå´©æºƒ?"
> - "Dockerå®¹å™¨å’Œè™šæ‹Ÿæœºæœ‰ä»€ä¹ˆåŒºåˆ«?"
> - "DevOpsçš„æ ¸å¿ƒç†å¿µæ˜¯ä»€ä¹ˆ?"
> 
> AIä¼šç”¨é€šä¿—çš„è¯­è¨€è§£é‡Šè¿™äº›æ¦‚å¿µ,å¸®ä½ å¿«é€Ÿå»ºç«‹åŸºç¡€è®¤çŸ¥ã€‚

### Agentå¦‚ä½•æ”¹å˜æ¸¸æˆè§„åˆ™

**1. æ°¸ä¸ä¼‘æ¯çš„ç›‘æ§ä¸å“åº”**

Agentå¯ä»¥24/7è¿è¡Œ,å®šæœŸæ£€æŸ¥ç³»ç»Ÿå¥åº·çŠ¶æ€,å¹¶åœ¨å‘ç°é—®é¢˜æ—¶ç«‹å³å“åº”ã€‚å®ƒä¸éœ€è¦ç¡çœ ,ä¸ä¼šç–²åŠ³,ä¸ä¼šå› ä¸ºå‡æœŸè€Œç¼ºå¸­ã€‚

```yaml
# HEARTBEAT.md - Agentçš„å®šæœŸæ£€æŸ¥æ¸…å•
checks:
  - name: kubernetes-health
    interval: 5min
    action: check_pod_status
  
  - name: disk-usage
    interval: 15min
    action: monitor_disk_space
    threshold: 80%
  
  - name: certificate-expiry
    interval: 1day
    action: check_ssl_certificates
    alert_days: 7
  
  - name: backup-verification
    interval: 1hour
    action: verify_latest_backup
```

**2. è‡ªåŠ¨åŒ–çš„çŸ¥è¯†ç§¯ç´¯**

æ¯æ¬¡Agentå¤„ç†é—®é¢˜æ—¶,å®ƒéƒ½ä¼šè®°å½•è¯¦ç»†çš„è¯Šæ–­è¿‡ç¨‹å’Œè§£å†³æ–¹æ¡ˆã€‚è¿™äº›è®°å½•ä¼šå­˜å‚¨åœ¨Gitç‰ˆæœ¬æ§åˆ¶çš„çŸ¥è¯†åº“ä¸­,æˆä¸ºç»„ç»‡çš„è¿ç»´èµ„äº§ã€‚

```markdown
# memory/incidents/2024-02-20-pod-restart.md

## äº‹ä»¶: api-gateway Podé¢‘ç¹é‡å¯

**æ£€æµ‹æ—¶é—´**: 2024-02-20 03:15:22
**ä¸¥é‡çº§åˆ«**: Warning

### è¯Šæ–­è¿‡ç¨‹
1. æ£€æŸ¥PodçŠ¶æ€: CrashLoopBackOff
2. æŸ¥çœ‹å®¹å™¨æ—¥å¿—: OutOfMemoryError
3. æ£€æŸ¥èµ„æºé™åˆ¶: memory limit 512Mi
4. æ£€æŸ¥å®é™…ä½¿ç”¨: æ¥è¿‘500Mi,è§¦å‘OOM

### é‡‡å–è¡ŒåŠ¨
- ä¸´æ—¶æªæ–½: é‡å¯Pod(æˆåŠŸ)
- æ°¸ä¹…ä¿®å¤: æäº¤PRå¢åŠ memory limitåˆ°1Gi
- PRé“¾æ¥: https://git.example.com/infra/k8s/pull/123

### é¢„é˜²å»ºè®®
- è®¾ç½®å†…å­˜ä½¿ç”¨å‘Šè­¦é˜ˆå€¼ä¸º70%
- å¢åŠ Horizontal Pod Autoscaler
- ä¼˜åŒ–åº”ç”¨å†…å­˜ä½¿ç”¨

### çŸ¥è¯†æ›´æ–°
æ›´æ–°åˆ°çŸ¥è¯†åº“: docs/troubleshooting/k8s-memory-issues.md
```

**3. æ¸è¿›å¼è‡ªåŠ¨åŒ–**

Agentç³»ç»Ÿå¯ä»¥ä»ç®€å•çš„ç›‘æ§å’Œå‘Šè­¦å¼€å§‹,é€æ­¥æ¼”è¿›åˆ°è‡ªä¸»ä¿®å¤ã€‚ä½ å¯ä»¥æ ¹æ®å›¢é˜Ÿçš„èˆ’é€‚åº¦å’Œç³»ç»Ÿçš„é£é™©çº§åˆ«,é€‰æ‹©åˆé€‚çš„è‡ªåŠ¨åŒ–å±‚æ¬¡ã€‚

| è‡ªåŠ¨åŒ–å±‚æ¬¡ | Agentè¡Œä¸º | é€‚ç”¨åœºæ™¯ | ç¤ºä¾‹ |
|-----------|----------|---------|------|
| **Level 1** | åªç›‘æ§,å‘ç°é—®é¢˜ç«‹å³å‘Šè­¦ | é«˜é£é™©æ“ä½œ,æ–°éƒ¨ç½²çš„ç³»ç»Ÿ | æ•°æ®åº“ä¸»ä»åˆ‡æ¢æ£€æµ‹ |
| **Level 2** | æä¾›è¯Šæ–­å»ºè®®,ç­‰å¾…äººå·¥ç¡®è®¤ | ä¸­ç­‰é£é™©,éœ€è¦äººå·¥åˆ¤æ–­ | å»ºè®®å›æ»šéƒ¨ç½² |
| **Level 3** | è‡ªåŠ¨ä¿®å¤,äº‹åé€šçŸ¥ | ä½é£é™©,å¸¸è§é—®é¢˜ | é‡å¯å´©æºƒçš„Pod |
| **Level 4** | å®Œå…¨è‡ªä¸»,åªåœ¨å¼‚å¸¸æ—¶å‘Šè­¦ | æä½é£é™©,æˆç†Ÿåœºæ™¯ | è¯ä¹¦è‡ªåŠ¨ç»­æœŸ |

### çœŸå®æ”¶ç›Š:æŸåˆ›ä¸šå…¬å¸çš„æ¡ˆä¾‹

ä¸€å®¶30äººçš„SaaSåˆ›ä¸šå…¬å¸å®æ–½äº†Self-healing Agentç³»ç»Ÿåçš„å˜åŒ–:

**å®æ–½å‰(3ä¸ªæœˆæ•°æ®)**:
- å¹³å‡æ¯å‘¨å¤œé—´å‘Šè­¦: 4.2æ¬¡
- å¹³å‡å“åº”æ—¶é—´: 23åˆ†é’Ÿ
- è¿ç»´äººå‘˜ç¡çœ è´¨é‡: ğŸ˜«ğŸ˜«ğŸ˜«
- é‡å¤æ€§æ•…éšœå æ¯”: 73%

**å®æ–½å(3ä¸ªæœˆæ•°æ®)**:
- Agentè‡ªåŠ¨å¤„ç†çš„äº‹ä»¶: 87%
- éœ€è¦äººå·¥ä»‹å…¥çš„äº‹ä»¶: 13%
- å¹³å‡å“åº”æ—¶é—´: 2åˆ†é’Ÿ(Agent)
- è¿ç»´äººå‘˜ç¡çœ è´¨é‡: ğŸ˜ŠğŸ˜ŠğŸ˜Š
- å‡å°‘çš„On-callå‹åŠ›: æ˜¾è‘—

**æˆæœ¬æ•ˆç›Š**:
- Agentå¼€å‘å’Œç»´æŠ¤æˆæœ¬: çº¦40å·¥æ—¶/æœˆ
- èŠ‚çœçš„è¿ç»´å“åº”æ—¶é—´: çº¦160å·¥æ—¶/æœˆ
- ROI: 400%
- é™„åŠ ä»·å€¼: å›¢é˜Ÿå£«æ°”æå‡,çŸ¥è¯†ç§¯ç´¯

> ğŸ“š **æ·±å…¥å­¦ä¹ **
> 
> æƒ³äº†è§£æ›´å¤šå…³äºè‡ªåŠ¨åŒ–å±‚æ¬¡å’Œé£é™©è¯„ä¼°çš„å†…å®¹?å¯ä»¥é—®AI:
> - "DevOpsä¸­çš„è‡ªåŠ¨åŒ–æˆç†Ÿåº¦æ¨¡å‹æœ‰å“ªäº›?"
> - "å¦‚ä½•è¯„ä¼°è¿ç»´æ“ä½œçš„é£é™©çº§åˆ«?"
> - "Site Reliability Engineering(SRE)çš„æ ¸å¿ƒåŸåˆ™æ˜¯ä»€ä¹ˆ?"

## 11.2 Self-healingæ¨¡å¼æ·±åº¦å®è·µ[^self-healing-ch11]

ç°åœ¨è®©æˆ‘ä»¬æ„å»ºä¸€ä¸ªå®Œæ•´çš„è‡ªæ„ˆå¼æœåŠ¡å™¨ç³»ç»Ÿã€‚è¿™ä¸ªæ¡ˆä¾‹ä¼šå±•ç¤ºä»å¥åº·ç›‘æ§åˆ°è‡ªåŠ¨ä¿®å¤çš„å®Œæ•´æµç¨‹,æ¶‰åŠçœŸå®çš„DevOpså·¥å…·æ ˆã€‚

[^self-healing-ch11]: æ¡ˆä¾‹æ¥æºï¼š[Self-Healing Home Server](https://github.com/hesamsheikh/awesome-openclaw-usecases/blob/main/usecases/self-healing-home-server.md)ï¼Œawesome-openclaw-usecases ç¤¾åŒºè´¡çŒ®

### ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OpenClaw Agent                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Health Check â”‚  â”‚  Diagnosis   â”‚  â”‚    Repair    â”‚  â”‚
â”‚  â”‚   Scripts    â”‚â†’ â”‚    Engine    â”‚â†’ â”‚   Actions    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                                â”‚
        â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
        â”‚  Cron    â”‚                    â”‚   Git    â”‚
        â”‚ Schedulerâ”‚                    â”‚  Audit   â”‚
        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚        â”‚        â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â–¼â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚ SSH   â”‚ â”‚K8s â”‚ â”‚Terraformâ”‚
â”‚Serversâ”‚ â”‚API â”‚ â”‚ Ansible â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒç»„ä»¶è®¾è®¡

**1. å¥åº·æ£€æŸ¥å±‚(Health Check Layer)**

è¿™æ˜¯Agentçš„"æ„ŸçŸ¥å™¨å®˜",å®šæœŸæ”¶é›†ç³»ç»ŸçŠ¶æ€ä¿¡æ¯ã€‚

```bash
#!/bin/bash
# scripts/health-check.sh

set -euo pipefail

# æ£€æŸ¥ç£ç›˜ä½¿ç”¨ç‡
check_disk_usage() {
    local threshold=80
    local usage=$(df -h / | awk 'NR==2 {print $5}' | sed 's/%//')
    
    if [ "$usage" -gt "$threshold" ]; then
        echo "CRITICAL: Disk usage at ${usage}%"
        return 1
    else
        echo "OK: Disk usage at ${usage}%"
        return 0
    fi
}

# æ£€æŸ¥å…³é”®æœåŠ¡
check_services() {
    local services=("nginx" "postgresql" "redis")
    
    for service in "${services[@]}"; do
        if systemctl is-active --quiet "$service"; then
            echo "OK: $service is running"
        else
            echo "CRITICAL: $service is not running"
            return 1
        fi
    done
    return 0
}

# æ£€æŸ¥K8s PodçŠ¶æ€
check_k8s_pods() {
    local namespace="production"
    
    # è·å–æ‰€æœ‰éRunningçŠ¶æ€çš„Pod
    local failing_pods=$(kubectl get pods -n "$namespace" \
        --field-selector=status.phase!=Running \
        -o json | jq -r '.items[].metadata.name')
    
    if [ -n "$failing_pods" ]; then
        echo "CRITICAL: Failing pods in $namespace:"
        echo "$failing_pods"
        return 1
    else
        echo "OK: All pods running in $namespace"
        return 0
    fi
}

# æ£€æŸ¥è¯ä¹¦æœ‰æ•ˆæœŸ
check_ssl_certificates() {
    local domains=("api.example.com" "app.example.com")
    local warn_days=7
    
    for domain in "${domains[@]}"; do
        local expiry_date=$(echo | openssl s_client -servername "$domain" \
            -connect "$domain":443 2>/dev/null | openssl x509 -noout -enddate \
            | cut -d= -f2)
        
        local expiry_epoch=$(date -d "$expiry_date" +%s)
        local now_epoch=$(date +%s)
        local days_left=$(( ($expiry_epoch - $now_epoch) / 86400 ))
        
        if [ "$days_left" -lt "$warn_days" ]; then
            echo "WARNING: SSL certificate for $domain expires in $days_left days"
            return 1
        else
            echo "OK: SSL certificate for $domain valid for $days_left days"
        fi
    done
    return 0
}

# ä¸»æ£€æŸ¥æµç¨‹
main() {
    echo "=== Health Check Report $(date) ==="
    
    check_disk_usage
    check_services
    check_k8s_pods
    check_ssl_certificates
    
    echo "=== End of Report ==="
}

main "$@"
```

> ğŸ”§ **é‡åˆ°é”™è¯¯?**
> 
> è¿è¡Œå¥åº·æ£€æŸ¥è„šæœ¬æ—¶é‡åˆ°é—®é¢˜?æŠŠé”™è¯¯ä¿¡æ¯å¤åˆ¶ç»™AI:
> - "æˆ‘è¿è¡Œhealth-check.shæ—¶æŠ¥é”™: [ç²˜è´´é”™è¯¯], æ˜¯ä»€ä¹ˆåŸå› ?"
> - "kubectlå‘½ä»¤æ‰¾ä¸åˆ°,å¦‚ä½•å®‰è£…å’Œé…ç½®?"
> - "å¦‚ä½•é…ç½®SSHå…å¯†ç ç™»å½•åˆ°è¿œç¨‹æœåŠ¡å™¨?"

**2. è¯Šæ–­å¼•æ“(Diagnosis Engine)**

å½“å¥åº·æ£€æŸ¥å‘ç°é—®é¢˜æ—¶,Agentéœ€è¦æ·±å…¥åˆ†ææ ¹æœ¬åŸå› ã€‚

```python
# scripts/diagnosis.py

import subprocess
import json
from datetime import datetime, timedelta

class DiagnosisEngine:
    def __init__(self):
        self.findings = []
    
    def diagnose_pod_crash(self, pod_name, namespace="production"):
        """è¯Šæ–­Podå´©æºƒçš„åŸå› """
        
        # 1. è·å–PodçŠ¶æ€
        pod_status = self._get_pod_status(pod_name, namespace)
        self.findings.append(f"PodçŠ¶æ€: {pod_status['phase']}")
        
        # 2. æ£€æŸ¥æœ€è¿‘çš„å®¹å™¨æ—¥å¿—
        logs = self._get_container_logs(pod_name, namespace, tail=100)
        
        # 3. åˆ†æå¸¸è§é”™è¯¯æ¨¡å¼
        if "OutOfMemoryError" in logs or "OOMKilled" in pod_status.get("reason", ""):
            self.findings.append("è¯Šæ–­: å†…å­˜ä¸è¶³å¯¼è‡´Podè¢«OOM Killerç»ˆæ­¢")
            self.findings.append("å»ºè®®: å¢åŠ memory limitæˆ–ä¼˜åŒ–åº”ç”¨å†…å­˜ä½¿ç”¨")
            return "OOM"
        
        elif "CrashLoopBackOff" in pod_status.get("status", ""):
            restart_count = pod_status.get("restartCount", 0)
            self.findings.append(f"è¯Šæ–­: Podåå¤å´©æºƒ,å·²é‡å¯{restart_count}æ¬¡")
            
            # æ£€æŸ¥å¯åŠ¨æ¢é’ˆ
            if "Liveness probe failed" in logs:
                self.findings.append("åŸå› : Liveness probeå¤±è´¥")
                return "LIVENESS_FAILED"
            elif "Readiness probe failed" in logs:
                self.findings.append("åŸå› : Readiness probeå¤±è´¥")
                return "READINESS_FAILED"
            else:
                self.findings.append("åŸå› : åº”ç”¨å¯åŠ¨å¤±è´¥,æ£€æŸ¥æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯")
                return "STARTUP_FAILED"
        
        elif "ImagePullBackOff" in pod_status.get("status", ""):
            self.findings.append("è¯Šæ–­: æ— æ³•æ‹‰å–å®¹å™¨é•œåƒ")
            self.findings.append("å»ºè®®: æ£€æŸ¥é•œåƒåç§°ã€tagå’Œä»“åº“æƒé™")
            return "IMAGE_PULL_FAILED"
        
        # 4. æ£€æŸ¥èµ„æºé…é¢
        resource_usage = self._get_resource_usage(pod_name, namespace)
        if resource_usage['cpu_percent'] > 90:
            self.findings.append(f"è­¦å‘Š: CPUä½¿ç”¨ç‡ {resource_usage['cpu_percent']}%")
        if resource_usage['memory_percent'] > 90:
            self.findings.append(f"è­¦å‘Š: å†…å­˜ä½¿ç”¨ç‡ {resource_usage['memory_percent']}%")
        
        return "UNKNOWN"
    
    def diagnose_disk_full(self, hostname):
        """è¯Šæ–­ç£ç›˜ç©ºé—´ä¸è¶³"""
        
        # 1. æ‰¾å‡ºå ç”¨ç©ºé—´æœ€å¤šçš„ç›®å½•
        cmd = f"ssh {hostname} 'du -sh /var/* 2>/dev/null | sort -rh | head -10'"
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        
        self.findings.append("ç£ç›˜ç©ºé—´å ç”¨TOP 10:")
        self.findings.append(result.stdout)
        
        # 2. æ£€æŸ¥æ—¥å¿—æ–‡ä»¶å¤§å°
        log_dirs = ["/var/log", "/var/log/nginx", "/var/log/postgresql"]
        for log_dir in log_dirs:
            cmd = f"ssh {hostname} 'du -sh {log_dir} 2>/dev/null'"
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
            self.findings.append(f"{log_dir}: {result.stdout.strip()}")
        
        # 3. æ£€æŸ¥æ˜¯å¦æœ‰å¤§å‹core dumps
        cmd = f"ssh {hostname} 'find /var -name core.* -size +100M 2>/dev/null'"
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        if result.stdout.strip():
            self.findings.append("å‘ç°å¤§å‹core dumpæ–‡ä»¶:")
            self.findings.append(result.stdout)
        
        return "DISK_FULL"
    
    def _get_pod_status(self, pod_name, namespace):
        """è·å–PodçŠ¶æ€"""
        cmd = f"kubectl get pod {pod_name} -n {namespace} -o json"
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        pod_data = json.loads(result.stdout)
        
        status = pod_data['status']
        return {
            'phase': status.get('phase'),
            'reason': status.get('reason', ''),
            'status': status.get('containerStatuses', [{}])[0].get('state', {}),
            'restartCount': status.get('containerStatuses', [{}])[0].get('restartCount', 0)
        }
    
    def _get_container_logs(self, pod_name, namespace, tail=100):
        """è·å–å®¹å™¨æ—¥å¿—"""
        cmd = f"kubectl logs {pod_name} -n {namespace} --tail={tail}"
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        return result.stdout
    
    def _get_resource_usage(self, pod_name, namespace):
        """è·å–èµ„æºä½¿ç”¨ç‡"""
        cmd = f"kubectl top pod {pod_name} -n {namespace}"
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        
        # è§£æè¾“å‡º(ç¤ºä¾‹: NAME CPU(cores) MEMORY(bytes))
        lines = result.stdout.strip().split('\n')
        if len(lines) > 1:
            parts = lines[1].split()
            return {
                'cpu_percent': float(parts[1].replace('m', '')) / 10,  # ç®€åŒ–è®¡ç®—
                'memory_percent': 75  # è¿™é‡Œéœ€è¦æ›´å¤æ‚çš„è®¡ç®—,ç®€åŒ–å¤„ç†
            }
        return {'cpu_percent': 0, 'memory_percent': 0}
    
    def get_report(self):
        """ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š"""
        return "\n".join(self.findings)

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    import sys
    
    engine = DiagnosisEngine()
    issue_type = sys.argv[1] if len(sys.argv) > 1 else "pod_crash"
    
    if issue_type == "pod_crash":
        pod_name = sys.argv[2]
        result = engine.diagnose_pod_crash(pod_name)
        print(f"è¯Šæ–­ç»“æœ: {result}")
        print("\nè¯¦ç»†æŠ¥å‘Š:")
        print(engine.get_report())
    elif issue_type == "disk_full":
        hostname = sys.argv[2]
        result = engine.diagnose_disk_full(hostname)
        print(f"è¯Šæ–­ç»“æœ: {result}")
        print("\nè¯¦ç»†æŠ¥å‘Š:")
        print(engine.get_report())
```

**3. ä¿®å¤æ‰§è¡Œå±‚(Repair Action Layer)**

åŸºäºè¯Šæ–­ç»“æœ,Agentå¯ä»¥æ‰§è¡Œç›¸åº”çš„ä¿®å¤æ“ä½œã€‚è¿™æ˜¯æœ€éœ€è¦è°¨æ…è®¾è®¡çš„éƒ¨åˆ†ã€‚

```python
# scripts/repair.py

import subprocess
import time
from datetime import datetime
import os

class RepairEngine:
    def __init__(self, dry_run=False):
        self.dry_run = dry_run
        self.actions_taken = []
        self.git_repo = "/home/agent/infrastructure"
    
    def repair_pod_oom(self, pod_name, namespace="production"):
        """ä¿®å¤OOMé—®é¢˜"""
        
        # 1. ç«‹å³é‡å¯Pod(ä¸´æ—¶æªæ–½)
        if not self.dry_run:
            self._restart_pod(pod_name, namespace)
            self.actions_taken.append(f"é‡å¯äº†Pod: {pod_name}")
        else:
            self.actions_taken.append(f"[DRY RUN] å°†é‡å¯Pod: {pod_name}")
        
        # 2. åˆ›å»ºPRå¢åŠ memory limit(æ°¸ä¹…ä¿®å¤)
        current_limit = self._get_memory_limit(pod_name, namespace)
        new_limit = self._calculate_new_limit(current_limit)
        
        pr_branch = f"fix/increase-memory-{pod_name}-{int(time.time())}"
        pr_message = f"Increase memory limit for {pod_name} from {current_limit} to {new_limit}"
        
        if not self.dry_run:
            self._create_pr_for_resource_change(
                pod_name, namespace, "memory", new_limit, 
                pr_branch, pr_message
            )
            self.actions_taken.append(f"åˆ›å»ºPR: {pr_branch}")
        else:
            self.actions_taken.append(f"[DRY RUN] å°†åˆ›å»ºPRå¢åŠ å†…å­˜åˆ° {new_limit}")
        
        return True
    
    def repair_disk_full(self, hostname):
        """ä¿®å¤ç£ç›˜ç©ºé—´ä¸è¶³"""
        
        # 1. æ¸…ç†æ—§æ—¥å¿—
        retention_days = 7
        if not self.dry_run:
            cmd = f"""ssh {hostname} 'find /var/log -name "*.log" -mtime +{retention_days} -delete'"""
            subprocess.run(cmd, shell=True)
            self.actions_taken.append(f"æ¸…ç†äº† {hostname} ä¸Šè¶…è¿‡ {retention_days} å¤©çš„æ—¥å¿—")
        else:
            self.actions_taken.append(f"[DRY RUN] å°†æ¸…ç† {hostname} ä¸Šçš„æ—§æ—¥å¿—")
        
        # 2. å‹ç¼©æœªå‹ç¼©çš„æ—¥å¿—
        if not self.dry_run:
            cmd = f"""ssh {hostname} 'find /var/log -name "*.log" -size +100M -exec gzip {{}} \\;'"""
            subprocess.run(cmd, shell=True)
            self.actions_taken.append(f"å‹ç¼©äº†å¤§å‹æ—¥å¿—æ–‡ä»¶")
        
        # 3. åˆ é™¤core dumps
        if not self.dry_run:
            cmd = f"""ssh {hostname} 'find /var -name core.* -delete'"""
            subprocess.run(cmd, shell=True)
            self.actions_taken.append(f"åˆ é™¤äº†core dumpæ–‡ä»¶")
        
        # 4. å¦‚æœè¿˜æ˜¯ä¸å¤Ÿ,åˆ›å»ºæ‰©å®¹ticket
        remaining_space = self._check_disk_space(hostname)
        if remaining_space < 20:  # å°‘äº20%
            self._create_expansion_ticket(hostname, remaining_space)
            self.actions_taken.append(f"åˆ›å»ºäº†ç£ç›˜æ‰©å®¹å·¥å•")
        
        return True
    
    def repair_certificate_expiry(self, domain):
        """ç»­æœŸSSLè¯ä¹¦"""
        
        # ä½¿ç”¨Let's Encryptè‡ªåŠ¨ç»­æœŸ
        if not self.dry_run:
            cmd = f"certbot renew --cert-name {domain}"
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
            
            if result.returncode == 0:
                self.actions_taken.append(f"æˆåŠŸç»­æœŸ {domain} çš„è¯ä¹¦")
                
                # é‡æ–°åŠ è½½nginx
                subprocess.run("systemctl reload nginx", shell=True)
                self.actions_taken.append("é‡æ–°åŠ è½½äº†nginxé…ç½®")
            else:
                self.actions_taken.append(f"è¯ä¹¦ç»­æœŸå¤±è´¥: {result.stderr}")
                return False
        else:
            self.actions_taken.append(f"[DRY RUN] å°†ç»­æœŸ {domain} çš„è¯ä¹¦")
        
        return True
    
    def repair_failed_deployment(self, deployment_name, namespace="production"):
        """å›æ»šå¤±è´¥çš„éƒ¨ç½²"""
        
        # 1. æ£€æŸ¥æœ€è¿‘çš„éƒ¨ç½²å†å²
        cmd = f"kubectl rollout history deployment/{deployment_name} -n {namespace}"
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        
        # 2. å›æ»šåˆ°ä¸Šä¸€ä¸ªç‰ˆæœ¬
        if not self.dry_run:
            cmd = f"kubectl rollout undo deployment/{deployment_name} -n {namespace}"
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
            
            if result.returncode == 0:
                self.actions_taken.append(f"æˆåŠŸå›æ»š {deployment_name}")
                
                # 3. ç­‰å¾…rolloutå®Œæˆ
                cmd = f"kubectl rollout status deployment/{deployment_name} -n {namespace}"
                subprocess.run(cmd, shell=True, timeout=300)
            else:
                self.actions_taken.append(f"å›æ»šå¤±è´¥: {result.stderr}")
                return False
        else:
            self.actions_taken.append(f"[DRY RUN] å°†å›æ»š {deployment_name}")
        
        return True
    
    def _restart_pod(self, pod_name, namespace):
        """é‡å¯Pod"""
        cmd = f"kubectl delete pod {pod_name} -n {namespace}"
        subprocess.run(cmd, shell=True)
        time.sleep(5)  # ç­‰å¾…Podé‡æ–°åˆ›å»º
    
    def _get_memory_limit(self, pod_name, namespace):
        """è·å–å½“å‰memory limit"""
        cmd = f"""kubectl get pod {pod_name} -n {namespace} -o jsonpath='{{.spec.containers[0].resources.limits.memory}}'"""
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        return result.stdout.strip()
    
    def _calculate_new_limit(self, current_limit):
        """è®¡ç®—æ–°çš„memory limit(å¢åŠ 50%)"""
        # ç®€åŒ–å¤„ç†: 512Mi -> 768Mi, 1Gi -> 1.5Gi
        if "Mi" in current_limit:
            value = int(current_limit.replace("Mi", ""))
            new_value = int(value * 1.5)
            return f"{new_value}Mi"
        elif "Gi" in current_limit:
            value = float(current_limit.replace("Gi", ""))
            new_value = value * 1.5
            return f"{new_value}Gi"
        return current_limit
    
    def _create_pr_for_resource_change(self, pod_name, namespace, resource_type, new_value, branch_name, commit_message):
        """åˆ›å»ºPRä¿®æ”¹èµ„æºé…ç½®"""
        os.chdir(self.git_repo)
        
        # 1. åˆ›å»ºæ–°åˆ†æ”¯
        subprocess.run(f"git checkout -b {branch_name}", shell=True)
        
        # 2. ä¿®æ”¹é…ç½®æ–‡ä»¶(è¿™é‡Œå‡è®¾ä½¿ç”¨kustomize)
        config_file = f"k8s/overlays/{namespace}/{pod_name}/kustomization.yaml"
        # å®é™…ä¿®æ”¹é€»è¾‘ä¼šæ›´å¤æ‚,è¿™é‡Œç®€åŒ–å¤„ç†
        
        # 3. æäº¤å˜æ›´
        subprocess.run(f"git add {config_file}", shell=True)
        subprocess.run(f"git commit -m '{commit_message}'", shell=True)
        
        # 4. æ¨é€å¹¶åˆ›å»ºPR(ä½¿ç”¨GitHub CLIæˆ–API)
        subprocess.run(f"git push origin {branch_name}", shell=True)
        subprocess.run(
            f"gh pr create --title '{commit_message}' --body 'Auto-generated by Self-healing Agent'",
            shell=True
        )
    
    def _check_disk_space(self, hostname):
        """æ£€æŸ¥å‰©ä½™ç£ç›˜ç©ºé—´ç™¾åˆ†æ¯”"""
        cmd = f"ssh {hostname} \"df -h / | awk 'NR==2 {{print 100-$5}}' | sed 's/%//'\""
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        return int(result.stdout.strip())
    
    def _create_expansion_ticket(self, hostname, remaining_space):
        """åˆ›å»ºç£ç›˜æ‰©å®¹å·¥å•"""
        # è¿™é‡Œå¯ä»¥é›†æˆåˆ°Jiraã€Linearç­‰é¡¹ç›®ç®¡ç†å·¥å…·
        ticket_content = f"""
        ä¸»æœº: {hostname}
        å‰©ä½™ç©ºé—´: {remaining_space}%
        åˆ›å»ºæ—¶é—´: {datetime.now()}
        ä¼˜å…ˆçº§: High
        
        éœ€è¦æ‰©å®¹æ ¹åˆ†åŒºå®¹é‡ã€‚
        """
        # å®é™…å®ç°ä¼šè°ƒç”¨APIåˆ›å»ºå·¥å•
        print(f"åˆ›å»ºå·¥å•:\n{ticket_content}")
    
    def get_report(self):
        """ç”Ÿæˆä¿®å¤æŠ¥å‘Š"""
        report = f"\n=== ä¿®å¤æŠ¥å‘Š {datetime.now()} ===\n"
        report += "\n".join(self.actions_taken)
        report += "\n=== æŠ¥å‘Šç»“æŸ ===\n"
        return report

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    import sys
    
    # é»˜è®¤æ˜¯dry-runæ¨¡å¼,éœ€è¦æ˜¾å¼ä¼ é€’--executeæ‰ä¼šçœŸæ­£æ‰§è¡Œ
    dry_run = "--execute" not in sys.argv
    
    engine = RepairEngine(dry_run=dry_run)
    
    issue_type = sys.argv[1]
    
    if issue_type == "pod_oom":
        pod_name = sys.argv[2]
        success = engine.repair_pod_oom(pod_name)
    elif issue_type == "disk_full":
        hostname = sys.argv[2]
        success = engine.repair_disk_full(hostname)
    elif issue_type == "cert_expiry":
        domain = sys.argv[2]
        success = engine.repair_certificate_expiry(domain)
    elif issue_type == "failed_deployment":
        deployment_name = sys.argv[2]
        success = engine.repair_failed_deployment(deployment_name)
    else:
        print(f"æœªçŸ¥çš„é—®é¢˜ç±»å‹: {issue_type}")
        sys.exit(1)
    
    print(engine.get_report())
    sys.exit(0 if success else 1)
```

> ğŸ’¡ **AIè¾…åŠ©æç¤º**
> 
> Pythonè„šæœ¬çœ‹èµ·æ¥å¤æ‚?å¯ä»¥é—®AIå¸®ä½ ç†è§£:
> - "è¿™æ®µPythonä»£ç åšäº†ä»€ä¹ˆ?èƒ½ç”¨ç®€å•çš„è¯­è¨€è§£é‡Šå—?"
> - "subprocess.runæ˜¯ä»€ä¹ˆ?å¦‚ä½•ä½¿ç”¨?"
> - "å¦‚ä½•è°ƒè¯•Pythonè„šæœ¬ä¸­çš„é”™è¯¯?"

### OpenClaw Agenté›†æˆ

ç°åœ¨è®©æˆ‘ä»¬æŠŠè¿™äº›è„šæœ¬é›†æˆåˆ°OpenClaw Agentä¸­,æ„å»ºä¸€ä¸ªçœŸæ­£æ™ºèƒ½çš„è‡ªæ„ˆç³»ç»Ÿã€‚

```markdown
# AGENTS.md - Self-healing Agenté…ç½®

ä½ æ˜¯ä¸€ä¸ªDevOpsè‡ªæ„ˆAgent,è´Ÿè´£24/7ç›‘æ§å’Œç»´æŠ¤åŸºç¡€è®¾æ–½ã€‚

## èŒè´£

1. **å®šæœŸå¥åº·æ£€æŸ¥**: æ¯5-15åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡å…³é”®ç³»ç»Ÿ
2. **é—®é¢˜è¯Šæ–­**: å‘ç°å¼‚å¸¸æ—¶æ·±å…¥åˆ†ææ ¹æœ¬åŸå› 
3. **è‡ªåŠ¨ä¿®å¤**: åœ¨å®‰å…¨èŒƒå›´å†…è‡ªä¸»æ‰§è¡Œä¿®å¤æ“ä½œ
4. **äº‹ä»¶è®°å½•**: è¯¦ç»†è®°å½•æ‰€æœ‰è¯Šæ–­å’Œä¿®å¤è¿‡ç¨‹
5. **äººå·¥å‡çº§**: è¶…å‡ºèƒ½åŠ›èŒƒå›´æ—¶ç«‹å³é€šçŸ¥äººç±»

## å·¥ä½œæµç¨‹

å½“æ”¶åˆ°heartbeatæ—¶:

1. è¿è¡Œ `/scripts/health-check.sh`
2. å¦‚æœå‘ç°é—®é¢˜:
   - ç«‹å³è¿è¡Œè¯Šæ–­: `python /scripts/diagnosis.py <issue_type> <params>`
   - è¯„ä¼°é£é™©çº§åˆ«
   - å¦‚æœé£é™©å¯æ§,è¿è¡Œä¿®å¤: `python /scripts/repair.py <issue_type> <params>`
   - è®°å½•å®Œæ•´è¿‡ç¨‹åˆ° `memory/incidents/YYYY-MM-DD-<issue>.md`
   - å¦‚æœæ˜¯é‡å¤§é—®é¢˜,ç«‹å³é€šçŸ¥ç®¡ç†å‘˜
3. å¦‚æœä¸€åˆ‡æ­£å¸¸,å›å¤ `HEARTBEAT_OK`

## å†³ç­–è§„åˆ™

### å¯ä»¥è‡ªåŠ¨ä¿®å¤(æ— éœ€ç¡®è®¤)
- Podå†…å­˜OOMå´©æºƒ â†’ é‡å¯Pod + åˆ›å»ºå¢åŠ å†…å­˜çš„PR
- ç£ç›˜ä½¿ç”¨ > 80% â†’ æ¸…ç†æ—§æ—¥å¿—
- SSLè¯ä¹¦ < 7å¤©è¿‡æœŸ â†’ è‡ªåŠ¨ç»­æœŸ
- å•ä¸ªPodå´©æºƒ â†’ é‡å¯

### éœ€è¦äººå·¥ç¡®è®¤
- æ•°æ®åº“ä¸»ä»åˆ‡æ¢
- å¤§è§„æ¨¡æœåŠ¡é‡å¯(> 10ä¸ªå®ä¾‹)
- ç£ç›˜æ‰©å®¹
- å®‰å…¨ç›¸å…³å˜æ›´

### å¿…é¡»ç«‹å³å‘Šè­¦
- æ•°æ®å¤‡ä»½å¤±è´¥
- ç”Ÿäº§æ•°æ®åº“ä¸å¯ç”¨
- å…³é”®APIæŒç»­é”™è¯¯ç‡ > 10%
- å¼‚å¸¸çš„èµ„æºæ¶ˆè€—(å¯èƒ½æ˜¯æ”»å‡»)

## å®‰å…¨é˜²æŠ¤

- æ‰€æœ‰å˜æ›´é€šè¿‡Git PR,ä¸ç›´æ¥ä¿®æ”¹ç”Ÿäº§ç¯å¢ƒ
- é‡è¦æ“ä½œæœ‰dry-runæ¨¡å¼,å…ˆæ¨¡æ‹Ÿå†æ‰§è¡Œ
- æ¯æ—¥å®¡è®¡æ—¥å¿—,æ£€æŸ¥Agentè¡Œä¸º
- å‡­è¯é€šè¿‡n8néš”ç¦»,Agentä¸ç›´æ¥æŒæœ‰
```

```yaml
# HEARTBEAT.md - å®šæœŸä»»åŠ¡é…ç½®

# Self-healing Agentçš„å¿ƒè·³æ£€æŸ¥æ¸…å•

last_check: 2024-02-20T10:15:00Z

# æ¯5åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡
frequent_checks:
  - name: k8s-pod-health
    command: /scripts/health-check.sh check_k8s_pods
    last_run: 2024-02-20T10:15:00Z
    last_status: OK
  
  - name: critical-services
    command: /scripts/health-check.sh check_services
    last_run: 2024-02-20T10:15:00Z
    last_status: OK

# æ¯15åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡
moderate_checks:
  - name: disk-usage
    command: /scripts/health-check.sh check_disk_usage
    last_run: 2024-02-20T10:00:00Z
    last_status: WARNING
    last_finding: "Disk usage at 82% on web-01"
  
  - name: resource-usage
    command: kubectl top nodes
    last_run: 2024-02-20T10:00:00Z
    last_status: OK

# æ¯å¤©æ‰§è¡Œä¸€æ¬¡
daily_checks:
  - name: ssl-certificates
    command: /scripts/health-check.sh check_ssl_certificates
    last_run: 2024-02-20T09:00:00Z
    last_status: OK
  
  - name: backup-verification
    command: /scripts/verify-backups.sh
    last_run: 2024-02-20T09:00:00Z
    last_status: OK
  
  - name: security-audit
    command: /scripts/audit-logs.sh
    last_run: 2024-02-20T09:00:00Z
    last_status: OK

# éœ€è¦å…³æ³¨çš„é—®é¢˜
active_issues:
  - issue: "web-01 disk usage high"
    detected: 2024-02-20T10:00:00Z
    status: "repair_in_progress"
    actions_taken:
      - "Cleaned old logs"
      - "Compressed large files"
    next_check: 2024-02-20T10:30:00Z
```

### Cronä»»åŠ¡é…ç½®

é™¤äº†å¿ƒè·³æ£€æŸ¥,æˆ‘ä»¬è¿˜å¯ä»¥è®¾ç½®ç²¾ç¡®çš„å®šæ—¶ä»»åŠ¡:

```bash
# crontab -e

# æ¯5åˆ†é’Ÿ: å…³é”®å¥åº·æ£€æŸ¥
*/5 * * * * /home/agent/openclaw cron health-check-critical

# æ¯15åˆ†é’Ÿ: å®Œæ•´å¥åº·æ£€æŸ¥
*/15 * * * * /home/agent/openclaw cron health-check-full

# æ¯å°æ—¶: èµ„æºä½¿ç”¨è¶‹åŠ¿åˆ†æ
0 * * * * /home/agent/openclaw cron analyze-resource-trends

# æ¯6å°æ—¶: å®¹é‡è§„åˆ’æ£€æŸ¥
0 */6 * * * /home/agent/openclaw cron capacity-planning

# æ¯å¤©å‡Œæ™¨1ç‚¹: å®Œæ•´ç³»ç»Ÿå®¡è®¡
0 1 * * * /home/agent/openclaw cron daily-audit

# æ¯å¤©å‡Œæ™¨2ç‚¹: å¤‡ä»½éªŒè¯
0 2 * * * /home/agent/openclaw cron verify-backups

# æ¯å‘¨æ—¥å‡Œæ™¨3ç‚¹: æ¸…ç†æ—§çš„äº‹ä»¶è®°å½•
0 3 * * 0 /home/agent/openclaw cron cleanup-old-incidents
```

### çœŸå®åœºæ™¯æ¼”ç»ƒ

è®©æˆ‘ä»¬é€šè¿‡å‡ ä¸ªçœŸå®åœºæ™¯,çœ‹çœ‹Agentå¦‚ä½•å¤„ç†é—®é¢˜ã€‚

**åœºæ™¯1: Kubernetes Podå†…å­˜æº¢å‡º**

```
[2024-02-20 03:15:22] Heartbeatè§¦å‘å¥åº·æ£€æŸ¥

[æ£€æŸ¥] kubectl get pods -n production
å‘ç°: api-gateway-7d9f5b8c6-x7k2m çŠ¶æ€ CrashLoopBackOff

[è¯Šæ–­] python diagnosis.py pod_crash api-gateway-7d9f5b8c6-x7k2m
ç»“æœ: OOM - å†…å­˜ä½¿ç”¨æ¥è¿‘limit 512Mi

[å†³ç­–] é£é™©çº§åˆ«: Low (å¯è‡ªåŠ¨ä¿®å¤)
- å½±å“: å•ä¸ªPod,æœ‰å…¶ä»–å‰¯æœ¬åœ¨è¿è¡Œ
- æ“ä½œ: é‡å¯Pod + åˆ›å»ºå¢åŠ å†…å­˜PR

[ä¿®å¤] python repair.py pod_oom api-gateway-7d9f5b8c6-x7k2m
âœ“ Podå·²é‡å¯,æ¢å¤æ­£å¸¸
âœ“ åˆ›å»ºPR: fix/increase-memory-api-gateway-1708398922
âœ“ PRé“¾æ¥: https://github.com/company/infra/pull/456

[è®°å½•] äº‹ä»¶å·²è®°å½•åˆ° memory/incidents/2024-02-20-api-gateway-oom.md

[é€šçŸ¥] Slackæ¶ˆæ¯å‘é€åˆ° #devops:
"ğŸ¤– Self-healing Agent å·²è‡ªåŠ¨å¤„ç† api-gateway OOMé—®é¢˜
- é‡å¯äº†å´©æºƒçš„Pod
- åˆ›å»ºäº†å¢åŠ å†…å­˜çš„PR (#456)
- è¯¦æƒ…: [é“¾æ¥åˆ°äº‹ä»¶è®°å½•]"

æ€»å“åº”æ—¶é—´: 2åˆ†23ç§’
äººå·¥ä»‹å…¥: æ— éœ€
```

**åœºæ™¯2: ç£ç›˜ç©ºé—´å‘Šè­¦**

```
[2024-02-20 14:30:15] ç£ç›˜ä½¿ç”¨ç‡æ£€æŸ¥

[æ£€æŸ¥] df -h on web-01
å‘ç°: ç£ç›˜ä½¿ç”¨ 87% (è¶…è¿‡é˜ˆå€¼ 80%)

[è¯Šæ–­] python diagnosis.py disk_full web-01
ç»“æœ: /var/log å ç”¨ 45GB, å¤§é‡æœªå‹ç¼©çš„nginxæ—¥å¿—

[å†³ç­–] é£é™©çº§åˆ«: Low (å¯è‡ªåŠ¨ä¿®å¤)
- å½±å“: ä¸å½±å“æœåŠ¡,åªæ˜¯æ¸…ç†ç©ºé—´
- æ“ä½œ: æ¸…ç†7å¤©å‰çš„æ—¥å¿—,å‹ç¼©å¤§æ–‡ä»¶

[ä¿®å¤] python repair.py disk_full web-01 --execute
âœ“ åˆ é™¤äº† 12GB çš„æ—§æ—¥å¿—
âœ“ å‹ç¼©äº† 18GB çš„å¤§å‹æ—¥å¿—æ–‡ä»¶
âœ“ åˆ é™¤äº† 3GB çš„core dumps
å½“å‰ä½¿ç”¨ç‡: 64%

[è®°å½•] äº‹ä»¶å·²è®°å½•åˆ° memory/incidents/2024-02-20-web-01-disk-cleanup.md

[é€šçŸ¥] ä½ä¼˜å…ˆçº§é€šçŸ¥(ä¸æ‰“æ–­å·¥ä½œ):
"ğŸ’¾ web-01ç£ç›˜æ¸…ç†å®Œæˆ: 87% â†’ 64%"

æ€»å“åº”æ—¶é—´: 8åˆ†15ç§’(åŒ…æ‹¬æ¸…ç†æ“ä½œ)
äººå·¥ä»‹å…¥: æ— éœ€
```

**åœºæ™¯3: éƒ¨ç½²å¤±è´¥å›æ»š**

```
[2024-02-20 18:45:30] ArgoCD webhookå‘Šè­¦: api-gatewayéƒ¨ç½²å¤±è´¥

[æ£€æŸ¥] kubectl rollout status deployment/api-gateway -n production
çŠ¶æ€: ProgressDeadlineExceeded - æ–°ç‰ˆæœ¬Podæ— æ³•å¯åŠ¨

[è¯Šæ–­] python diagnosis.py pod_crash api-gateway-7d9f5b8c6-y8m3n
ç»“æœ: STARTUP_FAILED - æ–°ç‰ˆæœ¬é…ç½®é”™è¯¯å¯¼è‡´å¯åŠ¨å¤±è´¥

[å†³ç­–] é£é™©çº§åˆ«: High (éœ€è¦å¿«é€Ÿå†³ç­–)
- å½±å“: ç”Ÿäº§ç¯å¢ƒ,è™½æœ‰æ—§ç‰ˆæœ¬Podåœ¨è¿è¡Œä½†æ­£åœ¨æ›¿æ¢
- æ“ä½œ: ç«‹å³å›æ»šåˆ°ä¸Šä¸€ä¸ªç¨³å®šç‰ˆæœ¬

[é€šçŸ¥] Slackå®æ—¶æ¶ˆæ¯åˆ° #incidents:
"ğŸš¨ api-gatewayéƒ¨ç½²å¤±è´¥,å‡†å¤‡å›æ»š
- æ–°ç‰ˆæœ¬Podæ— æ³•å¯åŠ¨
- å³å°†å›æ»šåˆ°ä¸Šä¸€ä¸ªç¨³å®šç‰ˆæœ¬
- 30ç§’åè‡ªåŠ¨æ‰§è¡Œ,å›å¤ 'ABORT' å–æ¶ˆ"

[ç­‰å¾…] 30ç§’... (æ— äººå–æ¶ˆ)

[ä¿®å¤] python repair.py failed_deployment api-gateway --execute
âœ“ å›æ»šåˆ° revision 23
âœ“ ç­‰å¾…rolloutå®Œæˆ...
âœ“ æ‰€æœ‰Podè¿è¡Œæ­£å¸¸

[è®°å½•] äº‹ä»¶å·²è®°å½•,åŒ…æ‹¬å¤±è´¥çš„deploymenté…ç½®

[é€šçŸ¥] Slackæ¶ˆæ¯:
"âœ… api-gatewayå·²æˆåŠŸå›æ»š
- å½“å‰ç‰ˆæœ¬: v1.2.3 (revision 23)
- æ‰€æœ‰Podå¥åº·
- éœ€è¦æ’æŸ¥v1.2.4å¤±è´¥åŸå› "

æ€»å“åº”æ—¶é—´: 3åˆ†45ç§’
äººå·¥ä»‹å…¥: ç›‘æ§ä½†æœªå–æ¶ˆ(è¢«åŠ¨ç¡®è®¤)
```

**åœºæ™¯4: SSLè¯ä¹¦å³å°†è¿‡æœŸ**

```
[2024-02-20 09:00:00] æ¯æ—¥è¯ä¹¦æ£€æŸ¥

[æ£€æŸ¥] check_ssl_certificates
å‘ç°: api.example.com è¯ä¹¦å°†åœ¨5å¤©åè¿‡æœŸ

[è¯Šæ–­] ç¡®è®¤æ˜¯Let's Encryptè¯ä¹¦,å¯è‡ªåŠ¨ç»­æœŸ

[å†³ç­–] é£é™©çº§åˆ«: Medium
- å½±å“: è¯ä¹¦è¿‡æœŸä¼šå¯¼è‡´æœåŠ¡ä¸å¯ç”¨
- æ“ä½œ: ç«‹å³ç»­æœŸ(æå‰è€Œéæœ€åä¸€åˆ»)

[ä¿®å¤] python repair.py cert_expiry api.example.com --execute
âœ“ è¿è¡Œ certbot renew
âœ“ æ–°è¯ä¹¦æœ‰æ•ˆæœŸè‡³ 2024-05-20
âœ“ é‡æ–°åŠ è½½nginxé…ç½®

[éªŒè¯] æ£€æŸ¥æ–°è¯ä¹¦
âœ“ api.example.com è¯ä¹¦æœ‰æ•ˆæœŸ: 90å¤©

[è®°å½•] ç»­æœŸæˆåŠŸè®°å½•

[é€šçŸ¥] ä½ä¼˜å…ˆçº§é€šçŸ¥:
"ğŸ”’ api.example.com SSLè¯ä¹¦å·²è‡ªåŠ¨ç»­æœŸ
- æ–°æœ‰æ•ˆæœŸ: 90å¤©
- ä¸‹æ¬¡æ£€æŸ¥: 85å¤©å"

æ€»å“åº”æ—¶é—´: 1åˆ†30ç§’
äººå·¥ä»‹å…¥: æ— éœ€
```

## 11.3 n8né›†æˆä¸å·¥ä½œæµè‡ªåŠ¨åŒ–

åœ¨ç¬¬7ç« æˆ‘ä»¬è®¨è®ºäº†n8nä½œä¸ºå‡­è¯éš”ç¦»å±‚çš„å®‰å…¨ä¼˜åŠ¿ã€‚åœ¨åŸºç¡€è®¾æ–½è‡ªåŠ¨åŒ–åœºæ™¯ä¸­,n8nè¿˜èƒ½æä¾›å¼ºå¤§çš„å·¥ä½œæµç¼–æ’èƒ½åŠ›ã€‚

### ä¸ºä»€ä¹ˆéœ€è¦n8n?

**1. å‡­è¯å®‰å…¨éš”ç¦»**

Agentä¸ç›´æ¥æŒæœ‰äº‘æœåŠ¡çš„APIå¯†é’¥ã€æ•°æ®åº“å¯†ç ç­‰æ•æ„Ÿå‡­è¯ã€‚æ‰€æœ‰éœ€è¦å‡­è¯çš„æ“ä½œé€šè¿‡n8nçš„Webhookæ¥å£è°ƒç”¨,å‡­è¯åªå­˜å‚¨åœ¨n8nä¸­ã€‚

```
Agent â†’ Webhook â†’ n8n â†’ AWS/GCP/Azure API
        (æ— å‡­è¯)   (å‡­è¯å­˜å‚¨)
```

**2. å¯è§†åŒ–è°ƒè¯•**

n8næä¾›å›¾å½¢åŒ–çš„å·¥ä½œæµç•Œé¢,æ¯æ¬¡æ‰§è¡Œéƒ½æœ‰è¯¦ç»†çš„æ—¥å¿—,å¯ä»¥æ¸…æ¥šåœ°çœ‹åˆ°æ•°æ®åœ¨å„ä¸ªèŠ‚ç‚¹é—´çš„æµè½¬ã€‚

**3. ä½ä»£ç é›†æˆ**

è¿æ¥ä¸åŒçš„æœåŠ¡å’ŒAPIä¸éœ€è¦å†™ä»£ç ,é€šè¿‡æ‹–æ‹½èŠ‚ç‚¹å³å¯å®Œæˆã€‚è¿™é™ä½äº†ç»´æŠ¤æˆæœ¬,ä¹Ÿè®©éç¨‹åºå‘˜èƒ½å¤Ÿå‚ä¸è‡ªåŠ¨åŒ–æµç¨‹è®¾è®¡ã€‚

### æ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OpenClaw Agent     â”‚
â”‚                     â”‚
â”‚  ç›‘æ§ã€è¯Šæ–­ã€å†³ç­–   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ Webhook
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      n8n            â”‚
â”‚                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Workflow 1:   â”‚  â”‚
â”‚  â”‚ Slack Alert   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Workflow 2:   â”‚  â”‚
â”‚  â”‚ Scale K8s     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Workflow 3:   â”‚  â”‚
â”‚  â”‚ Backup Status â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
      â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
      â–¼    â–¼    â–¼        â–¼
   Slack  K8s  AWS    Database
```

### å®æˆ˜æ¡ˆä¾‹: å‘Šè­¦é€šçŸ¥å·¥ä½œæµ

**n8n Workflow 1: æ™ºèƒ½å‘Šè­¦åˆ†å‘**

```json
{
  "name": "Infrastructure Alert Router",
  "nodes": [
    {
      "name": "Webhook",
      "type": "n8n-nodes-base.webhook",
      "parameters": {
        "path": "infra-alert",
        "responseMode": "responseNode",
        "authentication": "headerAuth"
      }
    },
    {
      "name": "Parse Alert",
      "type": "n8n-nodes-base.code",
      "parameters": {
        "jsCode": "const alert = $input.item.json;\n\n// æå–å…³é”®ä¿¡æ¯\nconst severity = alert.severity;\nconst service = alert.service;\nconst message = alert.message;\n\n// åˆ¤æ–­ä¸¥é‡ç¨‹åº¦\nlet emoji = 'ğŸ”µ';\nlet priority = 'low';\nlet channel = '#monitoring';\n\nif (severity === 'critical') {\n  emoji = 'ğŸš¨';\n  priority = 'high';\n  channel = '#incidents';\n} else if (severity === 'warning') {\n  emoji = 'âš ï¸';\n  priority = 'medium';\n  channel = '#alerts';\n}\n\nreturn {\n  json: {\n    severity,\n    service,\n    message,\n    emoji,\n    priority,\n    channel,\n    timestamp: new Date().toISOString()\n  }\n};"
      }
    },
    {
      "name": "Route by Severity",
      "type": "n8n-nodes-base.switch",
      "parameters": {
        "rules": {
          "rules": [
            {
              "value": "critical",
              "operation": "equal",
              "field": "severity"
            },
            {
              "value": "warning",
              "operation": "equal",
              "field": "severity"
            }
          ]
        }
      }
    },
    {
      "name": "Send to Slack",
      "type": "n8n-nodes-base.slack",
      "parameters": {
        "channel": "={{$json.channel}}",
        "text": "={{$json.emoji}} *{{$json.service}}* - {{$json.severity}}\n\n{{$json.message}}\n\n_Time: {{$json.timestamp}}_",
        "attachments": []
      },
      "credentials": {
        "slackApi": "slack-workspace"
      }
    },
    {
      "name": "Critical: Also Send SMS",
      "type": "n8n-nodes-base.twilio",
      "parameters": {
        "to": "+1234567890",
        "message": "CRITICAL ALERT: {{$json.service}} - {{$json.message}}"
      },
      "credentials": {
        "twilioApi": "twilio-account"
      }
    },
    {
      "name": "Log to Database",
      "type": "n8n-nodes-base.postgres",
      "parameters": {
        "operation": "insert",
        "table": "infrastructure_alerts",
        "columns": "severity,service,message,timestamp",
        "values": "={{$json.severity}},={{$json.service}},={{$json.message}},={{$json.timestamp}}"
      },
      "credentials": {
        "postgres": "alert-db"
      }
    },
    {
      "name": "Respond to Agent",
      "type": "n8n-nodes-base.respondToWebhook",
      "parameters": {
        "respondWith": "json",
        "responseBody": "{\"status\": \"alert_sent\", \"channels\": [\"{{$json.channel}}\"]}"
      }
    }
  ],
  "connections": {
    "Webhook": {"main": [[{"node": "Parse Alert"}]]},
    "Parse Alert": {"main": [[{"node": "Route by Severity"}]]},
    "Route by Severity": {
      "main": [
        [{"node": "Send to Slack"}, {"node": "Critical: Also Send SMS"}],
        [{"node": "Send to Slack"}]
      ]
    },
    "Send to Slack": {"main": [[{"node": "Log to Database"}]]},
    "Critical: Also Send SMS": {"main": [[{"node": "Log to Database"}]]},
    "Log to Database": {"main": [[{"node": "Respond to Agent"}]]}
  }
}
```

**Agentç«¯è°ƒç”¨**

```python
# ä»Agentå‘é€å‘Šè­¦åˆ°n8n
import requests

def send_alert(severity, service, message):
    webhook_url = "https://n8n.example.com/webhook/infra-alert"
    headers = {
        "Authorization": "Bearer <webhook-token>",
        "Content-Type": "application/json"
    }
    
    payload = {
        "severity": severity,
        "service": service,
        "message": message,
        "source": "self-healing-agent",
        "hostname": os.uname().nodename
    }
    
    response = requests.post(webhook_url, json=payload, headers=headers)
    return response.json()

# ä½¿ç”¨ç¤ºä¾‹
send_alert(
    severity="critical",
    service="api-gateway",
    message="Podå´©æºƒ,å·²è‡ªåŠ¨é‡å¯ã€‚æ­£åœ¨åˆ›å»ºå¢åŠ å†…å­˜çš„PRã€‚"
)
```

### å®æˆ˜æ¡ˆä¾‹: Kubernetesè‡ªåŠ¨æ‰©å®¹

**n8n Workflow 2: æ™ºèƒ½æ‰©å®¹å†³ç­–**

è¿™ä¸ªå·¥ä½œæµæ¥æ”¶Agentçš„èµ„æºä½¿ç”¨æ•°æ®,åˆ†æè¶‹åŠ¿,å¹¶åœ¨å¿…è¦æ—¶è‡ªåŠ¨æ‰©å®¹ã€‚

```
Workflowæµç¨‹:
1. Webhookæ¥æ”¶èµ„æºä½¿ç”¨æ•°æ®
2. æŸ¥è¯¢Prometheusè·å–å†å²è¶‹åŠ¿
3. ä½¿ç”¨æœºå™¨å­¦ä¹ æ¨¡å‹é¢„æµ‹æœªæ¥è´Ÿè½½
4. å¦‚æœé¢„æµ‹ä¼šè¶…è½½,è§¦å‘æ‰©å®¹
5. è°ƒç”¨Kubernetes APIå¢åŠ å‰¯æœ¬æ•°
6. å‘é€é€šçŸ¥åˆ°Slack
7. è®°å½•æ‰©å®¹äº‹ä»¶
```

**å…³é”®èŠ‚ç‚¹é…ç½®**

```javascript
// èŠ‚ç‚¹: åˆ†æèµ„æºä½¿ç”¨è¶‹åŠ¿
const current_cpu = $input.item.json.cpu_percent;
const current_memory = $input.item.json.memory_percent;
const pod_count = $input.item.json.pod_count;

// è·å–Prometheuså†å²æ•°æ®
const prometheus_url = "http://prometheus:9090/api/v1/query";
const query = `rate(container_cpu_usage_seconds_total{pod=~"api-gateway-.*"}[5m])`;

// ... çœç•¥HTTPè¯·æ±‚ä»£ç  ...

// ç®€å•çš„è¶‹åŠ¿åˆ†æ(å®é™…åº”è¯¥ç”¨æ›´å¤æ‚çš„æ¨¡å‹)
const avg_cpu_last_hour = 75.3;
const trend = (current_cpu - avg_cpu_last_hour) / avg_cpu_last_hour;

let should_scale = false;
let reason = "";

if (current_cpu > 80 && trend > 0.1) {
  should_scale = true;
  reason = `CPUä½¿ç”¨ç‡${current_cpu}%ä¸”å‘ˆä¸Šå‡è¶‹åŠ¿`;
} else if (current_memory > 85) {
  should_scale = true;
  reason = `å†…å­˜ä½¿ç”¨ç‡${current_memory}%`;
}

return {
  json: {
    should_scale,
    reason,
    current_pods: pod_count,
    recommended_pods: should_scale ? pod_count + 2 : pod_count
  }
};
```

```yaml
# èŠ‚ç‚¹: æ‰§è¡ŒKubernetesæ‰©å®¹
# ä½¿ç”¨n8nçš„KubernetesèŠ‚ç‚¹
Operation: Update
Resource: Deployment
Namespace: production
Name: api-gateway
Update:
  spec:
    replicas: {{$json.recommended_pods}}
```

> ğŸ”§ **é‡åˆ°é”™è¯¯?**
> 
> n8nå·¥ä½œæµè°ƒè¯•æŠ€å·§:
> - ç‚¹å‡»æ¯ä¸ªèŠ‚ç‚¹æŸ¥çœ‹è¾“å…¥/è¾“å‡ºæ•°æ®
> - ä½¿ç”¨"Execute Node"å•ç‹¬æµ‹è¯•æŸä¸ªèŠ‚ç‚¹
> - æ£€æŸ¥"Executions"æŸ¥çœ‹å†å²è¿è¡Œè®°å½•
> 
> é‡åˆ°é…ç½®é—®é¢˜?é—®AI:
> "n8nçš„KubernetesèŠ‚ç‚¹å¦‚ä½•é…ç½®?éœ€è¦ä»€ä¹ˆæƒé™?"
> "å¦‚ä½•åœ¨n8nä¸­å®‰å…¨å­˜å‚¨APIå¯†é’¥?"

### å®æˆ˜æ¡ˆä¾‹: ç›‘æ§æ•°æ®èšåˆ

**n8n Workflow 3: å¤šæºç›‘æ§æ•°æ®æ¨é€**

è¿™ä¸ªå·¥ä½œæµå®šæœŸä»å¤šä¸ªç›‘æ§ç³»ç»Ÿæ”¶é›†æ•°æ®,èšåˆåæ¨é€ç»™Agentè¿›è¡Œåˆ†æã€‚

```
æ•°æ®æº:
- Prometheus (åŸºç¡€è®¾æ–½æŒ‡æ ‡)
- CloudWatch (AWSèµ„æº)
- Datadog (APMæ•°æ®)
- PagerDuty (å‘Šè­¦å†å²)
- GitHub (éƒ¨ç½²äº‹ä»¶)

èšåˆé€»è¾‘:
1. æ¯15åˆ†é’Ÿè§¦å‘ä¸€æ¬¡
2. å¹¶è¡ŒæŸ¥è¯¢æ‰€æœ‰æ•°æ®æº
3. åˆå¹¶æ•°æ®åˆ°ç»Ÿä¸€æ ¼å¼
4. è®¡ç®—å…³é”®æŒ‡æ ‡(å¯ç”¨æ€§ã€é”™è¯¯ç‡ã€å»¶è¿Ÿ)
5. æ¨é€åˆ°Agentçš„webhook
6. Agentåˆ†ææ•°æ®,å†³å®šæ˜¯å¦éœ€è¦é‡‡å–è¡ŒåŠ¨
```

**Agentæ¥æ”¶èšåˆæ•°æ®**

```python
# Agent webhook endpoint
from flask import Flask, request, jsonify

app = Flask(__name__)

@app.route('/webhook/monitoring-data', methods=['POST'])
def receive_monitoring_data():
    data = request.json
    
    # æå–å…³é”®æŒ‡æ ‡
    availability = data['metrics']['availability']
    error_rate = data['metrics']['error_rate']
    p99_latency = data['metrics']['p99_latency']
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸
    issues = []
    
    if availability < 99.9:
        issues.append(f"å¯ç”¨æ€§ä¸‹é™åˆ° {availability}%")
    
    if error_rate > 1.0:
        issues.append(f"é”™è¯¯ç‡ {error_rate}% (æ­£å¸¸<1%)")
    
    if p99_latency > 1000:
        issues.append(f"P99å»¶è¿Ÿ {p99_latency}ms (æ­£å¸¸<500ms)")
    
    if issues:
        # è§¦å‘è¯Šæ–­æµç¨‹
        diagnosis = diagnose_performance_issue(data)
        
        # å¦‚æœå¯ä»¥ä¿®å¤,æ‰§è¡Œä¿®å¤
        if diagnosis['can_auto_fix']:
            repair_result = execute_repair(diagnosis)
            return jsonify({"status": "repaired", "actions": repair_result})
        else:
            # å‡çº§åˆ°äººå·¥å¤„ç†
            send_alert("warning", "Performance Issue", "\n".join(issues))
            return jsonify({"status": "escalated"})
    
    return jsonify({"status": "healthy"})
```

### n8nçš„å¯è§‚æµ‹æ€§ä¼˜åŠ¿

n8næœ€å¤§çš„ä¼˜åŠ¿ä¹‹ä¸€æ˜¯**å®Œæ•´çš„å¯è§‚æµ‹æ€§**ã€‚æ¯æ¬¡å·¥ä½œæµæ‰§è¡Œéƒ½ä¼šä¿ç•™è¯¦ç»†è®°å½•:

```
Execution #12345
Status: Success
Duration: 2.3s
Triggered: 2024-02-20 15:30:00

Node Executions:
â”œâ”€ Webhook                    âœ“  50ms
â”œâ”€ Parse Alert                âœ“  10ms  
â”œâ”€ Route by Severity          âœ“  5ms
â”œâ”€ Send to Slack              âœ“  380ms
â”œâ”€ Log to Database            âœ“  120ms
â””â”€ Respond to Webhook         âœ“  5ms

Input Data:
{
  "severity": "warning",
  "service": "api-gateway",
  "message": "High memory usage detected"
}

Output Data:
{
  "status": "alert_sent",
  "channels": ["#alerts"]
}
```

è¿™ç§å¯è§‚æµ‹æ€§åœ¨è°ƒè¯•è‡ªåŠ¨åŒ–æµç¨‹æ—¶æå…¶æœ‰ä»·å€¼ã€‚ä½ å¯ä»¥å‡†ç¡®åœ°çœ‹åˆ°:
- å“ªä¸€æ­¥å¤±è´¥äº†
- è¾“å…¥è¾“å‡ºæ•°æ®æ˜¯ä»€ä¹ˆ
- æ‰§è¡ŒèŠ±äº†å¤šé•¿æ—¶é—´
- é”™è¯¯å †æ ˆåœ¨å“ªé‡Œ

> ğŸ“š **æ·±å…¥å­¦ä¹ **
> 
> æƒ³æ›´æ·±å…¥äº†è§£n8n?å¯ä»¥é—®AI:
> - "n8nå’ŒZapierã€Make(Integromat)æœ‰ä»€ä¹ˆåŒºåˆ«?"
> - "å¦‚ä½•è®¾è®¡å®¹é”™çš„n8nå·¥ä½œæµ?"
> - "n8nå¯ä»¥éƒ¨ç½²åˆ°Kuberneteså—?æœ‰ä»€ä¹ˆæœ€ä½³å®è·µ?"

## 11.4 Observabilityä¼˜å…ˆ

è‡ªæ„ˆç³»ç»Ÿçš„å¯é æ€§å–å†³äº**å¯è§‚æµ‹æ€§**(Observability)ã€‚ä½ éœ€è¦çŸ¥é“Agentåœ¨åšä»€ä¹ˆ,ä¸ºä»€ä¹ˆè¿™æ ·åš,ä»¥åŠå®ƒåšå¾—å¯¹ä¸å¯¹ã€‚

### ä¸‰å¤§æ”¯æŸ±: æ—¥å¿—ã€æŒ‡æ ‡ã€è¿½è¸ª

**1. æ—¥å¿—(Logs)**

ç»“æ„åŒ–æ—¥å¿—æ˜¯Agentè¡Œä¸ºçš„è¯¦ç»†è®°å½•ã€‚

```python
# ä½¿ç”¨ç»“æ„åŒ–æ—¥å¿—
import structlog

logger = structlog.get_logger()

# æ¯ä¸ªé‡è¦æ“ä½œéƒ½è®°å½•
logger.info(
    "health_check_completed",
    check_type="k8s_pods",
    namespace="production",
    total_pods=15,
    failing_pods=0,
    duration_ms=234
)

logger.warning(
    "issue_detected",
    issue_type="pod_crash",
    pod_name="api-gateway-x7k2m",
    namespace="production",
    restart_count=3,
    last_error="OutOfMemoryError"
)

logger.info(
    "repair_initiated",
    repair_type="pod_restart",
    pod_name="api-gateway-x7k2m",
    risk_level="low",
    auto_approved=True
)

logger.info(
    "repair_completed",
    repair_type="pod_restart",
    pod_name="api-gateway-x7k2m",
    success=True,
    duration_ms=2340,
    new_pod_name="api-gateway-9g3h7"
)
```

**æ—¥å¿—èšåˆ: Loki + Grafana**

ä½¿ç”¨LokièšåˆAgentçš„æ—¥å¿—,åœ¨Grafanaä¸­å¯è§†åŒ–æŸ¥è¯¢ã€‚

```yaml
# promtailé…ç½®: æ”¶é›†Agentæ—¥å¿—
scrape_configs:
  - job_name: self-healing-agent
    static_configs:
      - targets:
          - localhost
        labels:
          job: agent
          environment: production
          __path__: /var/log/agent/*.log
    
    pipeline_stages:
      - json:
          expressions:
            level: level
            message: message
            check_type: check_type
            issue_type: issue_type
      
      - labels:
          level:
          check_type:
          issue_type:
```

**åœ¨Grafanaä¸­æŸ¥è¯¢**

```logql
# æŸ¥è¯¢æœ€è¿‘1å°æ—¶å†…çš„æ‰€æœ‰ä¿®å¤æ“ä½œ
{job="agent"} |= "repair_completed" | json

# æŸ¥è¯¢å¤±è´¥çš„ä¿®å¤æ“ä½œ
{job="agent"} |= "repair_completed" | json | success="false"

# ç»Ÿè®¡æ¯ç§é—®é¢˜ç±»å‹çš„é¢‘ç‡
sum by (issue_type) (
  count_over_time({job="agent"} |= "issue_detected" [1h])
)
```

**2. æŒ‡æ ‡(Metrics)**

å°†Agentçš„å…³é”®æŒ‡æ ‡å¯¼å‡ºåˆ°Prometheusã€‚

```python
# ä½¿ç”¨Prometheuså®¢æˆ·ç«¯åº“
from prometheus_client import Counter, Histogram, Gauge, start_http_server

# å®šä¹‰æŒ‡æ ‡
health_checks_total = Counter(
    'agent_health_checks_total',
    'Total number of health checks performed',
    ['check_type', 'status']
)

issues_detected_total = Counter(
    'agent_issues_detected_total',
    'Total number of issues detected',
    ['issue_type', 'severity']
)

repairs_total = Counter(
    'agent_repairs_total',
    'Total number of repair actions taken',
    ['repair_type', 'success']
)

repair_duration_seconds = Histogram(
    'agent_repair_duration_seconds',
    'Time spent performing repairs',
    ['repair_type']
)

active_issues = Gauge(
    'agent_active_issues',
    'Number of currently active issues',
    ['severity']
)

# åœ¨ä»£ç ä¸­æ›´æ–°æŒ‡æ ‡
def perform_health_check(check_type):
    start = time.time()
    try:
        result = run_check(check_type)
        health_checks_total.labels(
            check_type=check_type,
            status='success'
        ).inc()
        return result
    except Exception as e:
        health_checks_total.labels(
            check_type=check_type,
            status='failure'
        ).inc()
        raise
    finally:
        duration = time.time() - start
        logger.info("check_completed", check_type=check_type, duration=duration)

def execute_repair(repair_type, **params):
    start = time.time()
    try:
        result = do_repair(repair_type, **params)
        repairs_total.labels(
            repair_type=repair_type,
            success=True
        ).inc()
        return result
    except Exception as e:
        repairs_total.labels(
            repair_type=repair_type,
            success=False
        ).inc()
        raise
    finally:
        duration = time.time() - start
        repair_duration_seconds.labels(repair_type=repair_type).observe(duration)

# å¯åŠ¨Prometheus metricsæœåŠ¡å™¨
start_http_server(9090)
```

**PrometheusæŸ¥è¯¢ç¤ºä¾‹**

```promql
# æ¯å°æ—¶æ£€æµ‹åˆ°çš„é—®é¢˜æ•°é‡
rate(agent_issues_detected_total[1h])

# ä¿®å¤æˆåŠŸç‡
sum(rate(agent_repairs_total{success="true"}[5m])) 
/ 
sum(rate(agent_repairs_total[5m]))

# P95ä¿®å¤æ—¶é—´
histogram_quantile(0.95, 
  rate(agent_repair_duration_seconds_bucket[5m])
)

# å½“å‰æ´»è·ƒçš„ä¸¥é‡é—®é¢˜æ•°é‡
agent_active_issues{severity="critical"}
```

**åœ¨Grafanaä¸­åˆ›å»ºDashboard**

```json
{
  "dashboard": {
    "title": "Self-healing Agentç›‘æ§",
    "panels": [
      {
        "title": "å¥åº·æ£€æŸ¥çŠ¶æ€",
        "targets": [{
          "expr": "rate(agent_health_checks_total[5m])"
        }],
        "type": "graph"
      },
      {
        "title": "é—®é¢˜æ£€æµ‹é‡",
        "targets": [{
          "expr": "sum by (issue_type) (rate(agent_issues_detected_total[1h]))"
        }],
        "type": "graph"
      },
      {
        "title": "ä¿®å¤æˆåŠŸç‡",
        "targets": [{
          "expr": "sum(rate(agent_repairs_total{success=\"true\"}[5m])) / sum(rate(agent_repairs_total[5m])) * 100"
        }],
        "type": "singlestat"
      },
      {
        "title": "æ´»è·ƒé—®é¢˜",
        "targets": [{
          "expr": "agent_active_issues"
        }],
        "type": "table"
      }
    ]
  }
}
```

**3. è¿½è¸ª(Tracing)**

ä½¿ç”¨OpenTelemetryè¿½è¸ªAgentå¤„ç†äº‹ä»¶çš„å®Œæ•´é“¾è·¯ã€‚

```python
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.exporter.jaeger.thrift import JaegerExporter

# é…ç½®è¿½è¸ª
tracer_provider = TracerProvider()
jaeger_exporter = JaegerExporter(
    agent_host_name="localhost",
    agent_port=6831,
)
tracer_provider.add_span_processor(BatchSpanProcessor(jaeger_exporter))
trace.set_tracer_provider(tracer_provider)

tracer = trace.get_tracer(__name__)

# ä½¿ç”¨è¿½è¸ª
def handle_incident(incident_type, **params):
    with tracer.start_as_current_span("handle_incident") as span:
        span.set_attribute("incident.type", incident_type)
        span.set_attribute("incident.severity", params.get("severity"))
        
        # è¯Šæ–­é˜¶æ®µ
        with tracer.start_as_current_span("diagnose"):
            diagnosis = diagnose(incident_type, params)
            span.set_attribute("diagnosis.result", diagnosis['type'])
        
        # å†³ç­–é˜¶æ®µ
        with tracer.start_as_current_span("decision"):
            decision = make_decision(diagnosis)
            span.set_attribute("decision.action", decision['action'])
            span.set_attribute("decision.risk_level", decision['risk'])
        
        # ä¿®å¤é˜¶æ®µ(å¦‚æœæ‰¹å‡†)
        if decision['approved']:
            with tracer.start_as_current_span("repair"):
                result = execute_repair(decision['action'], diagnosis)
                span.set_attribute("repair.success", result['success'])
        
        return result
```

åœ¨Jaeger UIä¸­,ä½ å¯ä»¥çœ‹åˆ°å®Œæ•´çš„è°ƒç”¨é“¾:

```
handle_incident (2.5s)
â”œâ”€ diagnose (0.8s)
â”‚  â”œâ”€ get_pod_status (0.3s)
â”‚  â”œâ”€ get_container_logs (0.4s)
â”‚  â””â”€ analyze_error_pattern (0.1s)
â”œâ”€ decision (0.1s)
â””â”€ repair (1.6s)
   â”œâ”€ restart_pod (1.2s)
   â””â”€ create_pr (0.4s)
```

### ä¸»åŠ¨ vs è¢«åŠ¨ç›‘æ§

**è¢«åŠ¨ç›‘æ§**: ç­‰å¾…é—®é¢˜å‘ç”Ÿ,ç„¶åå“åº”

```
é—®é¢˜å‘ç”Ÿ â†’ å‘Šè­¦è§¦å‘ â†’ Agentæ£€æµ‹ â†’ è¯Šæ–­ä¿®å¤
```

è¿™æ˜¯ä¼ ç»Ÿçš„ç›‘æ§æ¨¡å¼,Agentæ‰®æ¼”"æ•‘ç«é˜Ÿå‘˜"è§’è‰²ã€‚

**ä¸»åŠ¨ç›‘æ§**: é¢„æµ‹é—®é¢˜,æå‰é¢„é˜²

```
Agentå®šæœŸæ£€æŸ¥ â†’ å‘ç°æ½œåœ¨é—®é¢˜ â†’ ä¸»åŠ¨ä¿®å¤ â†’ é¿å…æ•…éšœ
```

Self-healing Agentåº”è¯¥ä»¥**ä¸»åŠ¨ç›‘æ§ä¸ºä¸»**,è¢«åŠ¨å“åº”ä¸ºè¾…ã€‚

**ä¸»åŠ¨ç›‘æ§ç¤ºä¾‹**

```python
def proactive_health_check():
    """ä¸»åŠ¨å‘ç°æ½œåœ¨é—®é¢˜"""
    
    issues_found = []
    
    # 1. æ£€æŸ¥è¯ä¹¦æœ‰æ•ˆæœŸ
    certificates = get_all_certificates()
    for cert in certificates:
        days_left = cert['expiry_days']
        if days_left < 30:
            issues_found.append({
                'type': 'certificate_expiring',
                'severity': 'warning' if days_left > 7 else 'high',
                'domain': cert['domain'],
                'days_left': days_left,
                'action': 'renew_certificate'
            })
    
    # 2. æ£€æŸ¥ç£ç›˜å¢é•¿è¶‹åŠ¿
    disk_usage = get_disk_usage_trend(days=7)
    growth_rate = calculate_growth_rate(disk_usage)
    if growth_rate > 0:
        days_until_full = calculate_days_until_full(disk_usage, growth_rate)
        if days_until_full < 30:
            issues_found.append({
                'type': 'disk_filling_up',
                'severity': 'warning',
                'days_until_full': days_until_full,
                'action': 'schedule_cleanup'
            })
    
    # 3. æ£€æŸ¥å³å°†è¿‡æœŸçš„å¤‡ä»½ä¿ç•™
    backups = get_backup_retention_status()
    for backup in backups:
        if backup['retention_days_left'] < 3:
            issues_found.append({
                'type': 'backup_expiring',
                'severity': 'high',
                'backup_id': backup['id'],
                'action': 'extend_retention'
            })
    
    # 4. æ£€æŸ¥èµ„æºä½¿ç”¨è¶‹åŠ¿
    resource_trends = analyze_resource_trends(days=14)
    if resource_trends['cpu']['trend'] == 'increasing':
        weeks_until_limit = resource_trends['cpu']['weeks_until_80_percent']
        if weeks_until_limit < 4:
            issues_found.append({
                'type': 'cpu_trending_high',
                'severity': 'info',
                'weeks_until_limit': weeks_until_limit,
                'action': 'consider_scaling'
            })
    
    return issues_found

# å®šæœŸè¿è¡Œä¸»åŠ¨æ£€æŸ¥
def main_loop():
    while True:
        issues = proactive_health_check()
        
        for issue in issues:
            if issue['severity'] in ['high', 'critical']:
                # ä¸¥é‡é—®é¢˜ç«‹å³å¤„ç†
                handle_issue(issue)
            else:
                # ä½ä¼˜å…ˆçº§é—®é¢˜è®°å½•å¹¶è®¡åˆ’å¤„ç†
                schedule_issue(issue)
        
        time.sleep(3600)  # æ¯å°æ—¶ä¸€æ¬¡
```

### å‘Šè­¦ç–²åŠ³çš„é˜²æŠ¤

è¿‡å¤šçš„å‘Šè­¦ä¼šå¯¼è‡´"å‘Šè­¦ç–²åŠ³",æœ€ç»ˆè®©äººå¿½ç•¥æ‰€æœ‰å‘Šè­¦ã€‚Self-healing Agentåº”è¯¥æ™ºèƒ½åœ°ç­›é€‰å‘Šè­¦ã€‚

**å‘Šè­¦åˆ†çº§ç­–ç•¥**

```python
def should_alert_human(issue):
    """å†³å®šæ˜¯å¦éœ€è¦é€šçŸ¥äººç±»"""
    
    # Level 1: Agentå·²è‡ªåŠ¨ä¿®å¤,æ— éœ€é€šçŸ¥
    if issue['auto_fixed'] and issue['severity'] == 'low':
        return False
    
    # Level 2: Agentå·²è‡ªåŠ¨ä¿®å¤,ä½†è®°å½•é€šçŸ¥(ä¸ç´§æ€¥)
    if issue['auto_fixed'] and issue['severity'] in ['medium', 'high']:
        return {
            'notify': True,
            'urgency': 'low',
            'channel': 'slack',
            'summary': True  # åªå‘é€æ‘˜è¦,ä¸å‘é€è¯¦æƒ…
        }
    
    # Level 3: Agentæ— æ³•è‡ªåŠ¨ä¿®å¤,éœ€è¦äººå·¥ä»‹å…¥
    if not issue['can_auto_fix']:
        return {
            'notify': True,
            'urgency': 'high' if issue['severity'] == 'critical' else 'medium',
            'channel': 'slack+sms' if issue['severity'] == 'critical' else 'slack',
            'summary': False  # å‘é€å®Œæ•´è¯¦æƒ…
        }
    
    # Level 4: é‡å¤å‡ºç°çš„é—®é¢˜,æå‡ä¼˜å…ˆçº§
    if issue['occurrence_count'] > 3:
        return {
            'notify': True,
            'urgency': 'high',
            'channel': 'slack',
            'message': f"è¿™ä¸ªé—®é¢˜å·²ç»å‡ºç°{issue['occurrence_count']}æ¬¡äº†,éœ€è¦æ ¹æœ¬æ€§ä¿®å¤"
        }
    
    return False
```

**èšåˆå‘Šè­¦**

ä¸è¦æ¯ä¸ªé—®é¢˜éƒ½å‘ä¸€æ¡å‘Šè­¦,è€Œæ˜¯èšåˆåŒç±»é—®é¢˜ã€‚

```python
def aggregate_alerts(issues, window_minutes=15):
    """èšåˆæ—¶é—´çª—å£å†…çš„å‘Šè­¦"""
    
    aggregated = {}
    
    for issue in issues:
        key = (issue['type'], issue['service'])
        if key not in aggregated:
            aggregated[key] = {
                'type': issue['type'],
                'service': issue['service'],
                'count': 0,
                'first_seen': issue['timestamp'],
                'last_seen': issue['timestamp'],
                'examples': []
            }
        
        aggregated[key]['count'] += 1
        aggregated[key]['last_seen'] = issue['timestamp']
        if len(aggregated[key]['examples']) < 3:
            aggregated[key]['examples'].append(issue)
    
    # ç”Ÿæˆæ‘˜è¦æ¶ˆæ¯
    alerts = []
    for agg in aggregated.values():
        if agg['count'] == 1:
            alerts.append(format_single_alert(agg['examples'][0]))
        else:
            alerts.append(format_aggregated_alert(agg))
    
    return alerts

def format_aggregated_alert(agg):
    return f"""
ğŸ”” {agg['count']}ä¸ª {agg['type']} é—®é¢˜
æœåŠ¡: {agg['service']}
æ—¶é—´èŒƒå›´: {agg['first_seen']} - {agg['last_seen']}

ç¤ºä¾‹:
{format_examples(agg['examples'])}

å®Œæ•´åˆ—è¡¨: [æŸ¥çœ‹è¯¦æƒ…]
"""
```

> ğŸ’¡ **AIè¾…åŠ©æç¤º**
> 
> æƒ³äº†è§£æ›´å¤šå¯è§‚æµ‹æ€§å®è·µ?å¯ä»¥é—®AI:
> - "ä»€ä¹ˆæ˜¯SLIã€SLOã€SLA?å¦‚ä½•è®¾å®šåˆç†çš„ç›®æ ‡?"
> - "å¦‚ä½•è®¾è®¡ä¸ä¼šäº§ç”Ÿå‘Šè­¦ç–²åŠ³çš„å‘Šè­¦ç­–ç•¥?"
> - "Prometheuså’ŒGrafanaçš„æœ€ä½³å®è·µæ˜¯ä»€ä¹ˆ?"

### å®¡è®¡ä¸åˆè§„

Self-healing Agentä¼šè‡ªä¸»æ‰§è¡ŒåŸºç¡€è®¾æ–½å˜æ›´,å¿…é¡»æœ‰å®Œæ•´çš„å®¡è®¡è½¨è¿¹ã€‚

**å®¡è®¡æ—¥å¿—è®¾è®¡**

```markdown
# memory/audit/2024-02-20-actions.md

## 2024-02-20 å®¡è®¡æ—¥å¿—

### 03:15:22 - Podé‡å¯
- **æ“ä½œ**: é‡å¯Pod
- **å¯¹è±¡**: api-gateway-7d9f5b8c6-x7k2m
- **åŸå› **: OutOfMemoryError
- **é£é™©çº§åˆ«**: Low
- **æ‰¹å‡†æ–¹å¼**: è‡ªåŠ¨(ç¬¦åˆé¢„è®¾è§„åˆ™)
- **æ‰§è¡Œç»“æœ**: æˆåŠŸ
- **æ–°Pod**: api-gateway-9g3h7
- **Gitæäº¤**: [é“¾æ¥]

### 14:30:45 - ç£ç›˜æ¸…ç†
- **æ“ä½œ**: æ¸…ç†æ—¥å¿—æ–‡ä»¶
- **å¯¹è±¡**: web-01.example.com
- **åŸå› **: ç£ç›˜ä½¿ç”¨ç‡87%
- **é£é™©çº§åˆ«**: Low
- **æ‰¹å‡†æ–¹å¼**: è‡ªåŠ¨
- **æ‰§è¡Œç»“æœ**: æˆåŠŸ
- **é‡Šæ”¾ç©ºé—´**: 33GB
- **æœ€ç»ˆä½¿ç”¨ç‡**: 64%

### 18:45:50 - éƒ¨ç½²å›æ»š
- **æ“ä½œ**: å›æ»šDeployment
- **å¯¹è±¡**: api-gateway
- **åŸå› **: æ–°ç‰ˆæœ¬å¯åŠ¨å¤±è´¥
- **é£é™©çº§åˆ«**: High
- **æ‰¹å‡†æ–¹å¼**: è‡ªåŠ¨(å¸¦30ç§’äººå·¥å–æ¶ˆçª—å£)
- **äººå·¥å¹²é¢„**: æ— 
- **æ‰§è¡Œç»“æœ**: æˆåŠŸ
- **å›æ»šç‰ˆæœ¬**: v1.2.3 (revision 23)
```

**å®šæœŸå®¡è®¡æŠ¥å‘Š**

```python
def generate_weekly_audit_report():
    """ç”Ÿæˆæ¯å‘¨å®¡è®¡æŠ¥å‘Š"""
    
    week_start = datetime.now() - timedelta(days=7)
    actions = get_actions_since(week_start)
    
    report = {
        'period': f"{week_start.date()} to {datetime.now().date()}",
        'total_actions': len(actions),
        'by_type': count_by_field(actions, 'type'),
        'by_risk_level': count_by_field(actions, 'risk_level'),
        'by_approval': count_by_field(actions, 'approval_method'),
        'success_rate': calculate_success_rate(actions),
        'manual_interventions': count_manual_interventions(actions),
        'time_saved': estimate_time_saved(actions),
        'issues': []
    }
    
    # è¯†åˆ«éœ€è¦å…³æ³¨çš„æ¨¡å¼
    for action_type, count in report['by_type'].items():
        if count > 10:  # é¢‘ç¹å‘ç”Ÿ
            report['issues'].append({
                'type': 'frequent_issue',
                'action_type': action_type,
                'count': count,
                'recommendation': f"è€ƒè™‘æ ¹æœ¬æ€§ä¿®å¤ {action_type} é—®é¢˜"
            })
    
    # è¯†åˆ«å¤±è´¥ç‡é«˜çš„æ“ä½œ
    for action_type in report['by_type'].keys():
        type_actions = [a for a in actions if a['type'] == action_type]
        failure_rate = 1 - calculate_success_rate(type_actions)
        if failure_rate > 0.2:  # å¤±è´¥ç‡>20%
            report['issues'].append({
                'type': 'high_failure_rate',
                'action_type': action_type,
                'failure_rate': f"{failure_rate*100:.1f}%",
                'recommendation': f"æ£€æŸ¥ {action_type} çš„è‡ªåŠ¨ä¿®å¤é€»è¾‘"
            })
    
    # ç”ŸæˆmarkdownæŠ¥å‘Š
    return format_audit_report(report)
```

## å°ç»“

æœ¬ç« å±•ç¤ºäº†å¦‚ä½•æ„å»ºä¸€ä¸ªå®Œæ•´çš„è‡ªæ„ˆå¼åŸºç¡€è®¾æ–½ç³»ç»Ÿ:

**æ ¸å¿ƒè¦ç‚¹**:

1. **Agentçš„ä»·å€¼**: 24/7ç›‘æ§ã€è‡ªåŠ¨ä¿®å¤ã€çŸ¥è¯†ç§¯ç´¯,å°†è¿ç»´äººå‘˜ä»é‡å¤å·¥ä½œä¸­è§£æ”¾å‡ºæ¥

2. **Self-healingæ¨¡å¼**: å¥åº·æ£€æŸ¥ â†’ è¯Šæ–­åˆ†æ â†’ è‡ªåŠ¨ä¿®å¤ â†’ å®¡è®¡è®°å½•,å½¢æˆé—­ç¯

3. **å·¥å…·é›†æˆ**: SSHã€kubectlã€Terraformã€Ansibleä¸OpenClaw Agentçš„æ— ç¼é›†æˆ

4. **å®‰å…¨ç¬¬ä¸€**: å‡­è¯éš”ç¦»(n8n)ã€é˜²æŠ¤æ (Git PR)ã€å®¡è®¡æ—¥å¿—ã€äººå·¥ç¡®è®¤çª—å£

5. **å¯è§‚æµ‹æ€§ä¼˜å…ˆ**: æ—¥å¿—ã€æŒ‡æ ‡ã€è¿½è¸ªä¸‰å¤§æ”¯æŸ±,ä¸»åŠ¨ç›‘æ§è€Œéè¢«åŠ¨å“åº”

6. **æ¸è¿›å¼è‡ªåŠ¨åŒ–**: ä»Level 1(åªç›‘æ§)åˆ°Level 4(è‡ªä¸»ä¿®å¤),æ ¹æ®é£é™©å’Œæˆç†Ÿåº¦é€‰æ‹©

**å®æˆ˜å»ºè®®**:

- âœ… **ä»ç®€å•å¼€å§‹**: å…ˆè‡ªåŠ¨åŒ–ä½é£é™©ã€é«˜é¢‘ç‡çš„ä»»åŠ¡(å¦‚Podé‡å¯)
- âœ… **å»ºç«‹ä¿¡ä»»**: é€šè¿‡dry-runæ¨¡å¼å’Œè¯¦ç»†æ—¥å¿—è®©å›¢é˜Ÿä¿¡ä»»Agent
- âœ… **æŒç»­ä¼˜åŒ–**: å®šæœŸå®¡æŸ¥Agentè¡Œä¸º,ä¼˜åŒ–å†³ç­–é€»è¾‘
- âœ… **æ–‡æ¡£åŒ–çŸ¥è¯†**: æ¯æ¬¡äº‹ä»¶éƒ½æ˜¯å­¦ä¹ æœºä¼š,æ²‰æ·€åˆ°çŸ¥è¯†åº“
- âœ… **ç›‘æ§Agent**: Agentæœ¬èº«ä¹Ÿéœ€è¦ç›‘æ§,é¿å…"è°æ¥ç›‘æ§ç›‘æ§è€…"çš„é—®é¢˜

**ä¸‹ä¸€æ­¥**:

- ç¬¬12ç« æˆ‘ä»¬å°†è®¨è®ºçŸ¥è¯†ç®¡ç†ä¸å­¦ä¹ ç³»ç»Ÿ,å±•ç¤ºå¦‚ä½•è®©AgentæŒç»­ç§¯ç´¯è¿ç»´çŸ¥è¯†
- ç¬¬14ç« ä¼šæ·±å…¥Agentçš„å¯è§‚æµ‹æ€§ä¸è°ƒè¯•æŠ€å·§
- é™„å½•Aæä¾›äº†åŸºç¡€è®¾æ–½è‡ªåŠ¨åŒ–çš„å®‰å…¨æ£€æŸ¥æ¸…å•

è®°ä½: **æœ€å¥½çš„è‡ªæ„ˆç³»ç»Ÿä¸æ˜¯å¤„ç†é—®é¢˜æœ€å¿«çš„,è€Œæ˜¯è®©é—®é¢˜è¶Šæ¥è¶Šå°‘çš„**ã€‚é€šè¿‡æŒç»­å­¦ä¹ å’Œä¼˜åŒ–,Agentä¼šå¸®ä½ æ„å»ºä¸€ä¸ªè¶Šæ¥è¶Šç¨³å®šã€è¶Šæ¥è¶Šä¸éœ€è¦äººå·¥ä»‹å…¥çš„åŸºç¡€è®¾æ–½ã€‚

---

*"We can't solve problems by using the same kind of thinking we used when we created them." - Albert Einstein*

è‡ªåŠ¨åŒ–ä¸æ˜¯ç®€å•åœ°æŠŠæ‰‹åŠ¨æ“ä½œå˜æˆè„šæœ¬,è€Œæ˜¯é‡æ–°æ€è€ƒè¿ç»´å·¥ä½œçš„æœ¬è´¨ã€‚Agentç³»ç»Ÿè®©æˆ‘ä»¬ä»"æ•‘ç«"æ¨¡å¼è½¬å‘"é¢„é˜²"æ¨¡å¼,ä»"è¢«åŠ¨å“åº”"è½¬å‘"ä¸»åŠ¨ä¼˜åŒ–"ã€‚è¿™æ‰æ˜¯çœŸæ­£çš„DevOpsè½¬å‹ã€‚

---

## å‚è€ƒèµ„æ–™

æœ¬ç« å¼•ç”¨çš„æ¡ˆä¾‹å‡æ¥è‡ª [awesome-openclaw-usecases](https://github.com/hesamsheikh/awesome-openclaw-usecases) ç¤¾åŒºä»“åº“ï¼š

- [Self-Healing Home Server](https://github.com/hesamsheikh/awesome-openclaw-usecases/blob/main/usecases/self-healing-home-server.md)
- [n8n Workflow Orchestration](https://github.com/hesamsheikh/awesome-openclaw-usecases/blob/main/usecases/n8n-workflow-orchestration.md)
